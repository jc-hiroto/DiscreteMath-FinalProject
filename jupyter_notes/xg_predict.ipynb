{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:21.60208\n",
      "[1]\ttrain-rmse:19.55555\n",
      "[2]\ttrain-rmse:17.71453\n",
      "[3]\ttrain-rmse:16.06071\n",
      "[4]\ttrain-rmse:14.57054\n",
      "[5]\ttrain-rmse:13.23501\n",
      "[6]\ttrain-rmse:12.03721\n",
      "[7]\ttrain-rmse:10.94916\n",
      "[8]\ttrain-rmse:9.98378\n",
      "[9]\ttrain-rmse:9.10604\n",
      "[17:54:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:17.06433\n",
      "[1]\tvalidation_0-rmse:12.27140\n",
      "[2]\tvalidation_0-rmse:8.92523\n",
      "[3]\tvalidation_0-rmse:6.56554\n",
      "[4]\tvalidation_0-rmse:4.88678\n",
      "[5]\tvalidation_0-rmse:3.70939\n",
      "[6]\tvalidation_0-rmse:2.89225\n",
      "[7]\tvalidation_0-rmse:2.33943\n",
      "[8]\tvalidation_0-rmse:1.94412\n",
      "[9]\tvalidation_0-rmse:1.66867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=0,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=10, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=False,\n",
       "             subsample=1, tree_method='gpu_hist', validate_parameters=1,\n",
       "             verbosity=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if gpu-support is working.\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "# XGBoost API example\n",
    "params = {'tree_method': 'gpu_hist', 'max_depth': 3, 'learning_rate': 0.1}\n",
    "dtrain = xgb.DMatrix(boston.data, boston.target)\n",
    "xgb.train(params, dtrain, evals=[(dtrain, \"train\")])\n",
    "\n",
    "# sklearn API example\n",
    "gbm = xgb.XGBRegressor(silent=False, n_estimators=10, tree_method='gpu_hist')\n",
    "gbm.fit(boston.data, boston.target, eval_set=[(boston.data, boston.target)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:16:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:16:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accu: 0.6715727269002648\n",
      "         session    item_id  clicks  buy      pred\n",
      "0              1  214536500       1    0  0.273346\n",
      "1              1  214536506       1    0  0.273346\n",
      "2              1  214577561       1    0  0.253401\n",
      "3              1  214536502       1    0  0.273346\n",
      "4            128  214826615       1    0  0.351971\n",
      "...          ...        ...     ...  ...       ...\n",
      "414924  11561984  214712242       1    0  0.336728\n",
      "414925  11562112  214651419       1    0  0.287879\n",
      "414926  11562112  214829034       1    0  0.333839\n",
      "414927  11562113  214658096       1    0  0.256582\n",
      "414928  11562113  214855046       1    0  0.558185\n",
      "\n",
      "[414929 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('session_buy_data_2_14.csv')\n",
    "test = pd.read_csv('session_buy_data_1.csv')\n",
    "buy=data.groupby('buy').get_group(1)\n",
    "nobuy=data.groupby('buy').get_group(0)\n",
    "train = data\n",
    "x_train = train[['item_id','clicks']]\n",
    "y_train = train['buy']\n",
    "x_test = test[['item_id','clicks']]\n",
    "y_test = test['buy']\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 33)\n",
    "xgbc = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=24.5, seed=None,\n",
    "       silent=True, subsample=1,tree_method='gpu_hist')\n",
    "xgbc.fit(x_train, y_train)\n",
    "print(\"Accu:\",xgbc.score(x_test,y_test))\n",
    "a = xgbc.predict_proba(x_test)\n",
    "test['pred'] = xgbc.predict_proba(x_test)[:,1]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>sales</th>\n",
       "      <th>duration</th>\n",
       "      <th>clicks</th>\n",
       "      <th>items</th>\n",
       "      <th>buy</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>669</td>\n",
       "      <td>0</td>\n",
       "      <td>50.954</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1821</td>\n",
       "      <td>0</td>\n",
       "      <td>48.767</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2077</td>\n",
       "      <td>0</td>\n",
       "      <td>140.128</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>7197</td>\n",
       "      <td>0</td>\n",
       "      <td>372.736</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>8861</td>\n",
       "      <td>0</td>\n",
       "      <td>2333.206</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.789269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72209</th>\n",
       "      <td>11553437</td>\n",
       "      <td>0</td>\n",
       "      <td>168.321</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72217</th>\n",
       "      <td>11554717</td>\n",
       "      <td>0</td>\n",
       "      <td>197.962</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72228</th>\n",
       "      <td>11556509</td>\n",
       "      <td>3</td>\n",
       "      <td>453.607</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.455293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72237</th>\n",
       "      <td>11557917</td>\n",
       "      <td>2</td>\n",
       "      <td>358.004</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72254</th>\n",
       "      <td>11560733</td>\n",
       "      <td>6</td>\n",
       "      <td>283.208</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4040 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session  sales  duration  clicks  items  buy      prob\n",
       "4           669      0    50.954       3      1    1  0.554296\n",
       "11         1821      0    48.767       2      1    1  0.551624\n",
       "13         2077      0   140.128       5      3    1  0.588169\n",
       "45         7197      0   372.736       3      1    1  0.701910\n",
       "55         8861      0  2333.206       6      3    1  0.789269\n",
       "...         ...    ...       ...     ...    ...  ...       ...\n",
       "72209  11553437      0   168.321       5      3    1  0.643471\n",
       "72217  11554717      0   197.962       2      1    1  0.576822\n",
       "72228  11556509      3   453.607       3      3    1  0.455293\n",
       "72237  11557917      2   358.004       2      1    1  0.661919\n",
       "72254  11560733      6   283.208       6      5    1  0.645599\n",
       "\n",
       "[4040 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby('buy').get_group(1)#.sort_values(by=['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning data size: (2095656, 4)\n",
      "Testing data size: (72264, 4)\n",
      "P data size: (115125, 6)\n",
      "N data size: (1980531, 6)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for i in range(0,29):\n",
    "    rpath = \"train_data/train_data_p\"+str(i)+\".csv\"\n",
    "    #print(\"[TRAIN] Reading:\",rpath)\n",
    "    d0 = pd.read_csv(rpath)\n",
    "    data = pd.concat([data,d0])\n",
    "\n",
    "test = pd.read_csv('train_data/train_data_p29.csv')\n",
    "\n",
    "x_train = data[['sales','duration','items','clicks']]\n",
    "y_train = data['buy']\n",
    "x_test = test[['sales','duration','items','clicks']]\n",
    "y_test = test['buy']\n",
    "\n",
    "print(\"Trainning data size:\",x_train.shape)\n",
    "print(\"Testing data size:\",x_test.shape)\n",
    "\n",
    "buy = data.groupby('buy')\n",
    "ybuy = buy.get_group(1)\n",
    "nbuy = buy.get_group(0)\n",
    "print(\"P data size:\",ybuy.shape)\n",
    "print(\"N data size:\",nbuy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P data size: 115125\n",
      "N data size: 1980531\n",
      "ratio: 17.20330944625407\n"
     ]
    }
   ],
   "source": [
    "print(\"P data size:\",ybuy.shape[0])\n",
    "print(\"N data size:\",nbuy.shape[0])\n",
    "print(\"ratio:\",nbuy.shape[0]/ybuy.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning data size: (2095656, 4)\n",
      "Testing data size: (72264, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:20:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:20:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.7001411491198937\n",
      "Actually buys:      session  sales  duration  clicks  items  buy      prob\n",
      "4        669      0    50.954       3      1    1  0.554296\n",
      "11      1821      0    48.767       2      1    1  0.551624\n",
      "13      2077      0   140.128       5      3    1  0.588169\n",
      "45      7197      0   372.736       3      1    1  0.701910\n",
      "55      8861      0  2333.206       6      3    1  0.789269\n",
      "57      9117      0   685.298      11      8    1  0.771947\n",
      "64     10269      0   325.604       6      4    1  0.660132\n",
      "91     14621      0   850.296       4      4    1  0.518986\n",
      "105    16797      0  2637.298      20     12    1  0.890785\n",
      "142    22813      0  1233.838       6      4    1  0.780302\n",
      "153    24477      0   981.668      10      3    1  0.820067\n",
      "186    29853      0  1099.886       8      6    1  0.791720\n",
      "188    30109      0   184.616       7      3    1  0.752346\n",
      "190    30493      0    42.610       3      2    1  0.411108\n",
      "195    31261      0  2444.620      12      5    1  0.860754\n",
      "230    36893      0    76.762       2      1    1  0.538990\n",
      "238    38173      0  3002.475       3      3    1  0.353164\n",
      "243    38941      0  2277.064      11      7    1  0.836936\n",
      "257    41117      0   181.662      11      3    1  0.709615\n",
      "269    43037      0   441.860      11      6    1  0.822780\n"
     ]
    }
   ],
   "source": [
    "#train_new = pd.concat([ybuy,nbuy])\n",
    "train_new = data\n",
    "\n",
    "x_train = train_new[['sales','duration','items','clicks']]\n",
    "y_train = train_new['buy']\n",
    "x_test = test[['sales','duration','items','clicks']]\n",
    "y_test = test['buy']\n",
    "\n",
    "print(\"Trainning data size:\",x_train.shape)\n",
    "print(\"Testing data size:\",x_test.shape)\n",
    "\n",
    "#xgbc = xgb.XGBClassifier(\n",
    " #learning_rate =0.1,n_estimators=1000,max_depth=8,\n",
    " #min_child_weight=1,gamma=0,subsample=0.8,\n",
    " #colsample_bytree=0.8,objective= 'binary:logistic',\n",
    " #scale_pos_weight=17.2,seed=0,tree_method='gpu_hist')\n",
    "xgbc = xgb.XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "                         gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=5, min_child_weight=0.1, missing=None, n_estimators=1000,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=0, scale_pos_weight=17.2, seed=None,\n",
    "       silent=True, subsample=0.5,tree_method='gpu_hist')\n",
    "xgbc.fit(x_train, y_train)\n",
    "print(\"Accuracy:\",xgbc.score(x_test,y_test))\n",
    "test['prob']=xgbc.predict_proba(x_test)[:,1]\n",
    "print(\"Actually buys:\",test.groupby('buy').get_group(1).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actually buys:\n",
      "         session  sales  duration  clicks  items  buy      prob\n",
      "51596   8255389      5    51.808       5      2    1  0.020011\n",
      "72079  11532701      0     3.412       3      3    1  0.023472\n",
      "72087  11533981     10   168.055      10     10    1  0.056748\n",
      "12981   2076957      0    10.241       3      2    1  0.057155\n",
      "46745   7479197      4   671.583      27     25    1  0.061116\n",
      "33067   5290781      2     4.005       2      2    1  0.072340\n",
      "19408   3105309      0    63.663       4      4    1  0.073025\n",
      "10345   1655197      0   842.263      32     17    1  0.075592\n",
      "49361   7897757      3     8.913       3      3    1  0.087291\n",
      "72038  11526173      1     0.308       3      3    1  0.088625\n",
      "40587   6493981      6  5846.244       6      2    1  0.088736\n",
      "22640   3622429      0     0.062       2      2    1  0.102651\n",
      "40079   6412701      0   103.786       4      4    1  0.105455\n",
      "31028   4964509      0     0.769       2      1    1  0.108145\n",
      "53478   8556573      0     0.143       2      1    1  0.108145\n",
      "26035   4165661      0     0.263       2      1    1  0.108145\n",
      "7445    1191197      0     1.250       2      1    1  0.114564\n",
      "16688   2670109      0     1.243       2      1    1  0.114564\n",
      "37122   5939613      0     0.904       2      1    1  0.114564\n",
      "41702   6672413      0     1.174       2      1    1  0.114564\n",
      "11841   1894557      0     0.892       2      1    1  0.114564\n",
      "34640   5542429      4    46.561       4      4    1  0.119825\n",
      "32838   5254173      0    54.849       3      3    1  0.127299\n",
      "23663   3786141      0    40.562       3      3    1  0.129741\n",
      "9023    1443741      0     1.575       2      1    1  0.135373\n",
      "3483     557341      0  5206.215       6      2    1  0.135918\n",
      "71908  11505309      2    18.345       2      2    1  0.143521\n",
      "31389   5022237      0    70.640       5      4    1  0.144935\n",
      "56055   8968861      2    16.574       2      2    1  0.146439\n",
      "69432  11109149      2    18.147       2      1    1  0.148122\n",
      "42841   6854557      0    98.474       4      4    1  0.150234\n",
      "25546   4087453      0    11.821       2      2    1  0.152924\n",
      "19168   3066909      0    11.507       2      2    1  0.152924\n",
      "59244   9479069      0    12.246       2      2    1  0.152924\n",
      "31999   5119901      0    11.986       2      2    1  0.152924\n",
      "28066   4490653      0   107.630       4      4    1  0.154129\n",
      "57187   9149981     25  1336.821      37     30    1  0.154520\n",
      "9656    1544989      0  5592.140      49     25    1  0.155651\n",
      "29033   4645277      0    65.711       3      3    1  0.157668\n",
      "20666   3306653      0    29.913       3      3    1  0.158640\n",
      "9685    1549597      0    19.222       3      3    1  0.159747\n",
      "37942   6070813      2    30.681       2      2    1  0.159980\n",
      "69866  11178653      2    30.827       2      2    1  0.159980\n",
      "16310   2609693      0    74.078       3      3    1  0.160244\n",
      "26062   4170013      0    75.210       3      3    1  0.160244\n",
      "22333   3573277      0   115.262       4      4    1  0.160595\n",
      "10059   1609501      0   105.249       6      4    1  0.161446\n",
      "69970  11195293      4    73.183       4      1    1  0.162611\n",
      "44962   7194013      0   130.842       3      3    1  0.164523\n",
      "25385   4061597      0   129.409       3      3    1  0.164523\n",
      "Actually buys:\n",
      "         session  sales   duration  clicks  items  buy      prob\n",
      "65766  10522653     23   2522.153      33     24    1  0.999948\n",
      "20526   3284253      0   6370.810      34     11    1  0.999943\n",
      "46929   7508637     34   2115.384      34     10    1  0.999921\n",
      "43651   6984221     18   2201.484      27     23    1  0.999865\n",
      "38943   6230941     22   3013.606      28     24    1  0.999850\n",
      "66199  10591901     29   2071.032      31     24    1  0.999830\n",
      "24838   3974173      0   3748.049      41     31    1  0.999777\n",
      "57410   9185693     15   6056.461      15      7    1  0.999770\n",
      "33241   5318557     24   3128.149      29     27    1  0.999746\n",
      "70340  11254429     16   4138.138      22     16    1  0.999662\n",
      "60966   9754653     16   4007.847      23     15    1  0.999597\n",
      "64969  10395037      6  13860.259      10      7    1  0.999568\n",
      "14373   2299677      0   2267.169      61      2    1  0.999568\n",
      "49356   7896989     25   2381.387      32     24    1  0.999558\n",
      "57711   9233821     11   2699.211      20     13    1  0.999522\n",
      "22694   3631133      0   1600.455      31     21    1  0.999482\n",
      "39870   6379293     12   3798.303      32     28    1  0.999395\n",
      "34831   5573021     40    958.697      40     38    1  0.999387\n",
      "16246   2599453      0   3370.464      76      3    1  0.999381\n",
      "34306   5489053     10   1640.986      40     39    1  0.999308\n",
      "37589   6014237      3   1885.997      31     23    1  0.999193\n",
      "41518   6642973     11   3403.726      23     12    1  0.999189\n",
      "50649   8103837     16   5684.446      16      8    1  0.999179\n",
      "53065   8490397     23   1624.317      23     12    1  0.999124\n",
      "47055   7528861     25   2125.210      27     14    1  0.999049\n",
      "48990   7838493     20   1696.295      20     10    1  0.999038\n",
      "27390   4382493      0   1863.275      46     33    1  0.999020\n",
      "56077   8972317     18   1133.853      24      8    1  0.998983\n",
      "54564   8730269     19   1088.399      19      7    1  0.998687\n",
      "69839  11174301     12   4420.714      14      8    1  0.998664\n",
      "54459   8713501     12   1192.759      16      7    1  0.998629\n",
      "62196   9951389     21   1696.321      36     21    1  0.998489\n",
      "67078  10732573     15   3929.995      16     12    1  0.998472\n",
      "47929   7668637      3   4644.397      73     55    1  0.998421\n",
      "58328   9332509     23   8300.176      30     18    1  0.998399\n",
      "46517   7442717     18   3487.865      26     24    1  0.998263\n",
      "71310  11409693      7   2235.072      26     22    1  0.998243\n",
      "44617   7138717     12   1699.422      16     16    1  0.998189\n",
      "50153   8024477      5   6298.000      11      5    1  0.998046\n",
      "54715   8754461     12   2746.388      22     17    1  0.997976\n",
      "39370   6299293      9   2241.703      31     21    1  0.997652\n",
      "43715   6994461     20   1777.218      21     10    1  0.997620\n",
      "9742    1558813      0   7789.407      31     16    1  0.997003\n",
      "7878    1260573      0   1756.854      31     14    1  0.996679\n",
      "63130  10100893     31   1597.848      31      7    1  0.996590\n",
      "49052   7848349     39   2841.473      55     17    1  0.996384\n",
      "65681  10508957     14    845.397      14      5    1  0.996296\n",
      "34367   5498781     30    821.198      31     14    1  0.996201\n",
      "66274  10603933     22   1767.675      22     10    1  0.996123\n",
      "35090   5614493     25   1851.355      25     18    1  0.995900\n"
     ]
    }
   ],
   "source": [
    "print(\"Actually buys:\\n\",test.groupby('buy').get_group(1).sort_values(by=['prob']).head(50))\n",
    "print(\"Actually buys:\\n\",test.groupby('buy').get_group(1).sort_values(by=['prob'],ascending=False).head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.799\n",
      "AUC Score (Train): 0.882039\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-c9a3499c1b72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m  tree_method='gpu_hist')\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mmodelfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-126-c9a3499c1b72>\u001b[0m in \u001b[0;36mmodelfit\u001b[1;34m(alg, dtrain, predictors, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"AUC Score (Train): %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'buy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain_predprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mfeat_imp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mfeat_imp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Feature Importances'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature Importance Score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics   #Additional     scklearn functions\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "\n",
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['buy'],eval_metric='auc')\n",
    "    \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['buy'].values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['buy'], dtrain_predprob))\n",
    "                \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    \n",
    "target = 'buy'\n",
    "IDcol = 'session'\n",
    "\n",
    "predictors = [x for x in train.columns if x not in [target,IDcol]]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27,\n",
    " tree_method='gpu_hist')\n",
    "\n",
    "modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
